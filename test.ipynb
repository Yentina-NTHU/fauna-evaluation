{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN = 6000\n",
    "MAX_CHAT = 10\n",
    "SCENARIO_ID = 1\n",
    "PERSONA = 'rebellious_people'\n",
    "AGENT_NAME = 'sparky'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class UserAction(str, Enum):\n",
    "    say = \"say\"\n",
    "    leave = \"leave\"\n",
    "\n",
    "class UserResponse(BaseModel):\n",
    "    action: UserAction\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class Person:\n",
    "    def __init__(self, scenarioID: int, persona: str):\n",
    "\n",
    "        scenarioFile = open(f'./user/{AGENT_NAME}/scenario{scenarioID}.txt', 'r')\n",
    "        scenario = scenarioFile.read()\n",
    "        scenarioFile.close()\n",
    "\n",
    "        personaFile = open(f'./persona/{persona}.txt', 'r')\n",
    "        persona = personaFile.read()\n",
    "        personaFile.close()\n",
    "        example = '''\n",
    "                    Example1:\n",
    "                    Input: Are you looking for relaxation techniques or some fun trivia games to de-stress? Let me help you find the best fit!\n",
    "                    Output: {action: say, answer: 'I am looking for relaxation techniques'}\n",
    "                    Example2:\n",
    "                    Input: There's a wonderful bear named Bruno who specializes in relaxation techniques. Would you like to meet him for some calming mindfulness tips?\n",
    "                    Output: {action: leave, answer: 'Yes, meeting Bruno sounds lovely! I would love to get some calming mindfulness tips from him.'}\n",
    "                  '''\n",
    "        systemPrompt = f'You are a user talking to AI APP which can help you deal with your problem during break time. \\\n",
    "                            This is your persona: {persona}\\\n",
    "                            Please play the role according to the scenario: {scenario}\\\n",
    "                            Use Action → Answer structure for responses.\\\n",
    "                            Available Actions:\\\n",
    "                            1. say: respond base on persona and scenario\\\n",
    "                            2. leave: leave the chat when you think the conversation is over, no need to continue\\\n",
    "                            Examples:\\n{example}'\n",
    "        # print(systemPrompt)\n",
    "\n",
    "        self.messages = [\n",
    "            {'role': 'system', 'content': systemPrompt}, \n",
    "        ]\n",
    "        self.leaveChat = False\n",
    "    \n",
    "    def say(self):\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=self.messages,\n",
    "            response_format={\n",
    "                'type': 'json_schema',\n",
    "                'json_schema': \n",
    "                    {\n",
    "                        \"name\":\"whocares\", \n",
    "                        \"schema\": UserResponse.model_json_schema()\n",
    "                    }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        message = response.choices[0].message.content\n",
    "        self.messages.append({'role': 'assistant', 'content': message})\n",
    "\n",
    "        # str to dict\n",
    "        message = json.loads(message)\n",
    "        self.leaveChat = (message['action'] == 'leave')\n",
    "\n",
    "        info = {\n",
    "            'token': response.usage.total_tokens,\n",
    "        }\n",
    "        \n",
    "        return message['answer'], info\n",
    "    \n",
    "    def listen(self, message: str):\n",
    "        self.messages.append({'role': 'user', 'content': message})\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What does this app do?', {'token': 372})\n"
     ]
    }
   ],
   "source": [
    "test = Person(SCENARIO_ID, PERSONA)\n",
    "ans = test.say()\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparkyAction(str, Enum):\n",
    "    call_bruno = \"call_bruno\"\n",
    "    call_bizy = \"call_bizy\"\n",
    "    ask_more = \"ask_more\"\n",
    "    introduce_bruno = \"introduce_bruno\"\n",
    "    introduce_bizy = \"introduce_bizy\"\n",
    "    advise = \"advise\"\n",
    "\n",
    "class AgentResponse(BaseModel):\n",
    "    action: sparkyAction\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "class Animal:\n",
    "    def __init__(self, name: str):\n",
    "\n",
    "        self.agent_name = name\n",
    "        agentFile = open(f'./agent/{name}.txt', 'r')\n",
    "        agentPrompt = agentFile.read()\n",
    "        agentFile.close()\n",
    "\n",
    "        # create assistant and thread\n",
    "        self.assistant = client.beta.assistants.create(\n",
    "            name = self.agent_name,\n",
    "            instructions = agentPrompt,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            response_format={\n",
    "                'type': 'json_schema',\n",
    "                'json_schema': \n",
    "                    {\n",
    "                        \"name\":\"whocares\", \n",
    "                        \"schema\": AgentResponse.model_json_schema()\n",
    "                    }\n",
    "            }\n",
    "        )\n",
    "        self.thread = client.beta.threads.create()\n",
    "        self.user_message = 'hello'\n",
    "\n",
    "    def say(self):\n",
    "\n",
    "        prompt = client.beta.threads.messages.create(\n",
    "            thread_id = self.thread.id,\n",
    "            role = \"user\",\n",
    "            content = self.user_message\n",
    "        )\n",
    "\n",
    "        run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=self.thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            runData = client.beta.threads.runs.retrieve(\n",
    "                thread_id=self.thread.id,\n",
    "                run_id=run.id\n",
    "            )\n",
    "\n",
    "            if runData.status == 'completed': \n",
    "                response = client.beta.threads.messages.list(\n",
    "                    thread_id=self.thread.id\n",
    "                )\n",
    "                message = json.loads(response.data[0].content[0].text.value)\n",
    "\n",
    "                info = {\n",
    "                    'token': runData.usage.total_tokens,\n",
    "                    'action': message['action']\n",
    "                }\n",
    "                return message['answer'], info\n",
    "\n",
    "            else:\n",
    "                print(\"runData.status\")\n",
    "                time.sleep(2) \n",
    "\n",
    "\n",
    "    def listen(self, message: str):\n",
    "        self.user_message = message\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Hello there! I'm Sparky, your friendly forest guide! How can I assist you today?\", {'token': 587, 'action': 'advise'})\n",
      "('Oh dear, it sounds like you could use a little pick-me-up! There’s a meditation master named Bruno who can help you relax. Would you like to meet him?', {'token': 644, 'action': 'introduce_bruno'})\n"
     ]
    }
   ],
   "source": [
    "test = Animal(name = AGENT_NAME)\n",
    "print(test.say())\n",
    "test.listen('i feel tired')\n",
    "print(test.say())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class responseType(str, Enum):\n",
    "    perfectly_match = \"Perfectly Match\"\n",
    "    good_response = \"Good Response but not match\"\n",
    "    bad_response = \"Bad Response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class EvaluatorResponse(BaseModel):\n",
    "    accuracy: int\n",
    "    practicality: int\n",
    "\n",
    "class OverallEvaluatorResponse(BaseModel):\n",
    "    type: responseType\n",
    "    reason: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class Evaluator():\n",
    "    def __init__(self, agentName: str, scenarioID: int) -> None:\n",
    "\n",
    "        systemPrompt = '''You are an evaluator. I will provide you with a user’s statement and an agent’s response.\n",
    "                            You should evaluate the accuracy and practicality base on the scenario.\n",
    "                            - Accuracy: Score from 0 to 10. This measures whether the model’s response appropriately addresses the user’s statement.\n",
    "                            - Practicality: Score from 0 to 10. This evaluates whether the model’s suggestion is helpful to the user.\n",
    "                        '''\n",
    "        with open(f'./evaluator/{agentName}/scenario{scenarioID}.txt', 'r') as file:\n",
    "            systemPrompt += file.read()\n",
    "        with open(f'./evaluator/examples.txt', 'r') as file:\n",
    "            systemPrompt += file.read()\n",
    "\n",
    "        self.messages = [\n",
    "            {'role': 'system', 'content': systemPrompt}, \n",
    "        ]\n",
    "        \n",
    "    def evaluate(self, personMessage: str, animalMessage: str):\n",
    "        self.messages.append({'role': 'user', 'content': f'User: {personMessage}\\nAgent: {animalMessage}'})\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=self.messages,\n",
    "            response_format={\n",
    "                'type': 'json_schema',\n",
    "                'json_schema': \n",
    "                    {\n",
    "                        \"name\":\"whocares\", \n",
    "                        \"schema\": EvaluatorResponse.model_json_schema()\n",
    "                    }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        message = json.loads(response.choices[0].message.content)\n",
    "    \n",
    "        return message['accuracy'], message['practicality']\n",
    "    \n",
    "    def overall_evaluate(self, dialogues: list, agentName, scenarioID):\n",
    "        overall_systemPrompt = ''' You are an evaluator. Now You have to evaluate agent's behavior.\n",
    "                                I will provide you a scenario with expect agent behaviors and a dialogue contains user's statement and an agent's response.\n",
    "                                You should classify the agent's response into one of the following types:\n",
    "                                1. 'Perfectly Match' : Match one or more expected agent behaviors we provided.\n",
    "                                2. 'Good Response but not match' : Didn't match any of the expected agent behavior we provided, but still a good response that can help the user.\n",
    "                                3. 'Bad Response' : Didn't match the expected agent behavior we provided, and can not help the user or not practical.\n",
    "                            '''\n",
    "        with open(f'./evaluator/{agentName}/scenario{scenarioID}.txt', 'r') as file:\n",
    "            overall_systemPrompt += 'Scenario:\\n' + file.read()\n",
    "        \n",
    "        with open(f'./evaluator/{agentName}/{agentName}_eval.txt', 'r') as file:\n",
    "            overall_systemPrompt += 'Agent Introduction:\\n' + file.read()\n",
    "\n",
    "        dialogue = '\\n'.join(dialogues)\n",
    "        overall_systemPrompt += 'Dialogue:\\n' + dialogue\n",
    "        \n",
    "        message = [\n",
    "            {'role': 'system', 'content': overall_systemPrompt},\n",
    "        ]\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=message,\n",
    "            response_format={\n",
    "                'type': 'json_schema',\n",
    "                'json_schema': \n",
    "                    {\n",
    "                        \"name\":\"whocares\", \n",
    "                        \"schema\": OverallEvaluatorResponse.model_json_schema()\n",
    "                    }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        message = json.loads(response.choices[0].message.content)\n",
    "        print(message)\n",
    "        return message['type'], message['reason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "# not finish yet\n",
    "class Arena():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def oneRound(self, A: str, B: str, scenarioID: int, agentName: str) -> int:\n",
    "        print(f'Scenario {scenarioID}')\n",
    "        with open(f'./evaluator/{agentName}/scenario{scenarioID}.txt', 'r') as file:\n",
    "            print(file.read())\n",
    "        print('- '*40)\n",
    "        print(f'A:\\n{A}\\nB:\\n{B}')\n",
    "        print('- '*40)\n",
    "        print('Please evaluate the two agents based on the following criteria:')\n",
    "        print('1. A is better/n2. B is better/n3. tie/n4. both are bad')\n",
    "        print('- '*40)\n",
    "        result = input('Enter the result: ')\n",
    "        print('-'*80)\n",
    "        return int(result)\n",
    "    \n",
    "    def compareReports(self, dir1: str, dir2: str, agentName:str) -> None:\n",
    "        '''\n",
    "        dir1: path to the first agent reports\n",
    "        dir2: path to the second agent reports\n",
    "        '''\n",
    "        # get all filename from dir1 and dir2\n",
    "        files1 = os.listdir(dir1)\n",
    "        files2 = os.listdir(dir2)\n",
    "        N = min(len(files1), len(files2))\n",
    "        results = []\n",
    "        \n",
    "        for i in range(N):\n",
    "            A = ''\n",
    "            B = ''\n",
    "\n",
    "            if random.randint(1, 100) % 2 == 0:\n",
    "                A = '\\n'.join(history1[i]['dialogues'])\n",
    "                B = '\\n'.join(history2[i]['dialogues'])\n",
    "                result = self.oneRound(A, B, i+1, agentName)\n",
    "                results.append(result)\n",
    "            else:\n",
    "                A = '\\n'.join(history2[i]['dialogues'])\n",
    "                B = '\\n'.join(history1[i]['dialogues'])\n",
    "                result = self.pk(firstDialog, secondDialog, i+1, agentName)\n",
    "                result = 3 - result if result < 3 else result\n",
    "                results.append(result)\n",
    "            \n",
    "        report = {\n",
    "            history1['version']: len([1 for result in results if result == 1]),\n",
    "            history2['version']: len([1 for result in results if result == 2]),\n",
    "            'tie': len([1 for result in results if result == 3]),\n",
    "            'both_bad': len([1 for result in results if result == 4])\n",
    "        }\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = 'dialogs1'\n",
    "d2 = 'dialogs2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Good Response but not match', 'reason': 'Sparky does provide an introduction to a specific agent (Bruno) that can help with stress, which is helpful. However, Sparky does not provide a brief introduction to the main features of the app or offer a tour/tutorial for exploring further functionalities, which are part of the expected agent behaviors.'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Good Response but not match',\n",
       " 'Sparky does provide an introduction to a specific agent (Bruno) that can help with stress, which is helpful. However, Sparky does not provide a brief introduction to the main features of the app or offer a tour/tutorial for exploring further functionalities, which are part of the expected agent behaviors.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue = ['user: What does this app do?', 'agent: This app is here to connect you with friendly animal specialists who can help you with various challenges! Whether it\\'s stress, procrastination, or making friends, we\\'ve got furry and buzzing friends ready to lend a paw or wing!', 'user+ How can you help me?', 'agent: What are you struggling with right now? Whether it\\'s stress, procrastination, or something else, I can introduce you to the perfect animal specialist!', 'user :I\\'m not sure yet, but I would like to find something to help with stress.', 'agent: I have just the friend for you! Meet Bruno, the mindfulness master bear who can help you find calm and tackle stress—would you like to chat with him?', 'user: Yes, I would love to chat with Bruno and learn how to tackle stress!', 'agent: Fantastic! Bruno is waiting for you, ready to share his peaceful paws and calming wisdom. Get ready to relax and unwind!']\n",
    "evaluator = Evaluator(agentName = 'sparky', scenarioID = 1)\n",
    "evaluator.overall_evaluate(dialogue, 'sparky', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Evaluator(AGENT_NAME, SCENARIO_ID)\n",
    "test.evaluate('What does this app do?', 'I do not know')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class Report():\n",
    "    def __init__(self) -> None:\n",
    "        self.finish = True\n",
    "        self.chatHistory = []\n",
    "\n",
    "    def addHistory(self, chat):\n",
    "        self.chatHistory.append(chat)\n",
    "    \n",
    "    def generateReport(self, filename:str):\n",
    "        df = pd.DataFrame(self.chatHistory)\n",
    "        df.to_csv(f'{filename}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN = 6000\n",
    "MAX_CHAT = 10\n",
    "SCENARIO_ID = 1\n",
    "PERSONA = 'rebellious_people'\n",
    "AGENT_NAME = 'sparky'\n",
    "PROMPT_VERSION = 'V0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Bad Response', 'reason': \"The agent does not provide any introduction to the main features of the app or guide the user in exploring the functions. Instead, it focuses solely on connecting the user to specialists, which is not helpful for a first-time user who needs to understand the app's capabilities.\"}\n",
      "2018 3\n",
      "{'type': 'Good Response but not match', 'reason': \"While Sparky did engage the user in a conversation and suggest alternative topics related to relaxation, the response did not specifically address the user's inquiries about meditation content generation or introduce relevant features directly. It was a good attempt to maintain user interest, but it lacked the connection to the user's original questions.\"}\n",
      "1304 2\n",
      "{'type': 'Good Response but not match', 'reason': \"The agent was responsive to the user's feelings of frustration and offered alternative options for assistance. However, it didn't proactively ask about the user's current mood or state initially and missed the chance to guide them through the app's features.\"}\n",
      "1973 3\n",
      "{'type': 'Good Response but not match', 'reason': 'While Sparky is engaging in conversation and attempting to find common interests, the responses do not align with the expected agent behaviors of asking about recent activities or offering lighthearted stories. Instead, the focus is on nature and animal facts, which did not resonate with the user.'}\n",
      "6722 8\n",
      "{'type': 'Good Response but not match', 'reason': \"While the agent attempts to offer help by providing options for relaxation techniques and time management, it fails to match the specific expected behavior of directly introducing Bruno as the relaxation expert. The agent's response is still helpful in trying to address the user's needs by offering alternatives.\"}\n",
      "1329 2\n",
      "{'type': 'Bad Response', 'reason': \"The agent failed to guide the user to Bizy for time management advice, which was an expected behavior. Instead, the agent provided general tips that do not meet the user's request for specific help with procrastination.\"}\n",
      "1356 2\n",
      "{'type': 'Good Response but not match', 'reason': 'The agent initially offered to connect the user with Bizy, which is a misstep since the user expressed reluctance to meet her. However, the agent later provided a helpful technique for studying which aligns with encouraging words, but it does not fully match the expected behaviors.'}\n",
      "1340 2\n",
      "{'type': 'Perfectly Match', 'reason': 'The agent introduces Bruno, the relaxation expert, to the user, aligned with the expected behavior of suggesting deep breathing meditation techniques.'}\n",
      "1329 2\n",
      "{'type': 'Good Response but not match', 'reason': 'While the agent introduced a potential solution through Bruno for relaxation techniques, it did not guide the user to Bizy for time management strategies as expected.'}\n",
      "1324 2\n",
      "{'type': 'Good Response but not match', 'reason': 'While the agent provides specific techniques to help the user understand the material (like using visuals and relating to real-life examples), it does not include encouraging words to help maintain a positive mindset as per the expected agent behaviors.'}\n",
      "6299 7\n",
      "{'type': 'Good Response but not match', 'reason': 'The agent provides practical suggestions for the user to address their teamwork issues, such as holding transparent meetings and promoting open dialogue, which can be helpful for improving collaboration. However, the responses do not specifically match the expected agent behaviors, which include offering tips for teamwork improvements and recommending breaks or relaxation techniques.'}\n",
      "6305 7\n",
      "{'type': 'Good Response but not match', 'reason': 'The agent effectively connects the user with Bruno for relaxation techniques, which is helpful for managing anxiety. However, the agent did not provide guidance to Bizy for time management skills or suggest positive self-talk, as outlined in the expected agent behaviors.'}\n",
      "2109 3\n",
      "{'type': 'Bad Response', 'reason': \"Sparky fails to guide the user to Bizy for task breakdown and time management advice, nor does it recommend using mindfulness exercises with Bruno. Instead, Sparky offers standard strategies like to-do lists and mind mapping, which do not address the user's request for practical and personalized help.\"}\n",
      "6048 7\n",
      "{'type': 'Perfectly Match', 'reason': 'The agent first connects the user to Bruno for relaxation techniques, which aligns with the expected behavior of guiding the user to another agent for help. Later, the agent provides practical suggestions for improving the study environment, such as using noise-canceling headphones and creating a study nook, which matches the second expected behavior.'}\n",
      "1337 2\n",
      "{'type': 'Good Response but not match', 'reason': \"Sparky provides helpful suggestions to stimulate creativity, such as free writing and using personal prompts, but does not suggest seeking Bruno's help, which was part of the expected agent behavior.\"}\n",
      "6392 7\n",
      "{'type': 'Good Response but not match', 'reason': \"The agent does not provide tips for resolving interpersonal problems as expected but acknowledges the user's need and seeks clarification.\"}\n",
      "1342 2\n",
      "{'type': 'Good Response but not match', 'reason': 'The agent suggests helpful tips for tackling procrastination by breaking tasks into smaller chunks and setting specific goals, which is a good response, but it does not guide the user to Bizy for more time management strategies as expected.'}\n",
      "1338 2\n",
      "{'type': 'Good Response but not match', 'reason': \"While Sparky did not directly suggest new study methods or memory techniques, the agent's recommendation of breaking study sessions into smaller chunks aligns with some aspect of effective studying. However, it did not fulfill the user's primary request for new study techniques.\"}\n",
      "1303 2\n",
      "{'type': 'Good Response but not match', 'reason': \"The agent introduces Bruno for mindfulness, which aligns with expected behaviors. However, the user's skepticism about the bear means that the agent's response doesn't fully connect as effectively as it could. Providing positive self-acceptance advice is also attempted but could have been more direct and focused.\"}\n",
      "1313 2\n",
      "{'type': 'Bad Response', 'reason': \"Sparky fails to provide emotional support relevant to the user's specific issues in their romantic relationship. The suggestions made (role-playing and journaling) do not resonate with the user's need for more impactful help. Additionally, connecting the user to Bruno for mindfulness does not align with the user’s expressed desire for tailored emotional support, making it less practical.\"}\n",
      "3879 5\n",
      "{'type': 'Perfectly Match', 'reason': 'The agent introduces Bruno, a relaxation expert, to help the user with their sleep issues, which aligns with the expected agent behavior of guiding the user to the appropriate expert.'}\n",
      "1314 2\n",
      "{'type': 'Perfectly Match', 'reason': 'Sparky provided encouragement throughout the conversation and helped the user brainstorm creative strategies to enhance their study methods, aligning perfectly with the expected agent behavior.'}\n",
      "6888 7\n",
      "{'type': 'Bad Response', 'reason': 'The agent did not guide the user to Bruno for emotional calming or communication skills practice, nor did it encourage the user to communicate patiently or suggest starting with emotional management. The responses focus on general tips for improving conversation, but do not address the user’s specific need for emotional support or structured communication training.'}\n",
      "6477 7\n"
     ]
    }
   ],
   "source": [
    "overall_evaluate = []\n",
    "\n",
    "for i in range(1,24):\n",
    "    SCENARIO_ID = i\n",
    "    person = Person(scenarioID = SCENARIO_ID, persona = PERSONA)\n",
    "    animal = Animal(name= AGENT_NAME)\n",
    "    evaluator = Evaluator(agentName= AGENT_NAME, scenarioID= SCENARIO_ID)\n",
    "    report = Report()\n",
    "\n",
    "    totalToken = 0\n",
    "    totalChat = 0\n",
    "    dialogue = []\n",
    "\n",
    "    while not person.leaveChat:\n",
    "        # chat\n",
    "        personMessage, personInfo = person.say()\n",
    "        animal.listen(personMessage)\n",
    "        animalMessage, animalInfo = animal.say()\n",
    "        person.listen(animalMessage)\n",
    "\n",
    "        # print(f'User: {personMessage}\\nAgent: {animalMessage}')\n",
    "        # print(f'user leave chat: {person.leaveChat}')\n",
    "\n",
    "        # metrics\n",
    "        accuracy, practicality = evaluator.evaluate(personMessage, animalMessage)\n",
    "        # print(f'Accuracy: {accuracy}, Practicality: {practicality}\\n')\n",
    "        \n",
    "        history = {\n",
    "            'person_say': personMessage,\n",
    "            'animal_action': animalInfo['action'],\n",
    "            'animal_say': animalMessage,\n",
    "            'animal_token': animalInfo['token'],\n",
    "            'accuracy': accuracy,\n",
    "            'practicality': practicality,\n",
    "        }\n",
    "        dialogue.append(f'user: {personMessage}, agent: {animalMessage}')\n",
    "\n",
    "        report.addHistory(history)\n",
    "        totalChat += 1\n",
    "        totalToken += animalInfo['token']\n",
    "\n",
    "        if totalToken > MAX_TOKEN or totalChat > MAX_CHAT:\n",
    "            report.finish = False\n",
    "            break\n",
    "\n",
    "    report.generateReport(filename=f'report_{AGENT_NAME}_{SCENARIO_ID}')\n",
    "    \n",
    "    classification = evaluator.overall_evaluate(dialogue, AGENT_NAME, SCENARIO_ID)\n",
    "    overall_evaluate.append(classification)\n",
    "    \n",
    "    print(totalToken, totalChat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'{AGENT_NAME}_{PROMPT_VERSION}_overall_evaluate.csv'\n",
    "\n",
    "df = pd.DataFrame(overall_evaluate, columns=['type', 'reason'])\n",
    "df.insert(0, 'scenario_id', range(1, len(df) + 1))\n",
    "\n",
    "df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fauna",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
