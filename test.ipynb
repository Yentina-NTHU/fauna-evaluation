{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN = 6000\n",
    "MAX_CHAT = 10\n",
    "SCENARIO_ID = 1\n",
    "PERSONA = 'rebellious_people'\n",
    "AGENT_NAME = 'sparky'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class UserAction(str, Enum):\n",
    "    say = \"say\"\n",
    "    leave = \"leave\"\n",
    "\n",
    "class UserResponse(BaseModel):\n",
    "    action: UserAction\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class Person:\n",
    "    def __init__(self, scenarioID: int, persona: str):\n",
    "\n",
    "        scenarioFile = open(f'./user/{AGENT_NAME}/scenario{scenarioID}.txt', 'r')\n",
    "        scenario = scenarioFile.read()\n",
    "        scenarioFile.close()\n",
    "\n",
    "        personaFile = open(f'./persona/{persona}.txt', 'r')\n",
    "        persona = personaFile.read()\n",
    "        personaFile.close()\n",
    "        example = '''\n",
    "                    Example1:\n",
    "                    Input: Are you looking for relaxation techniques or some fun trivia games to de-stress? Let me help you find the best fit!\n",
    "                    Output: {action: say, answer: 'I am looking for relaxation techniques'}\n",
    "                    Example2:\n",
    "                    Input: There's a wonderful bear named Bruno who specializes in relaxation techniques. Would you like to meet him for some calming mindfulness tips?\n",
    "                    Output: {action: leave, answer: 'Yes, meeting Bruno sounds lovely! I would love to get some calming mindfulness tips from him.'}\n",
    "                  '''\n",
    "        systemPrompt = f'You are a user talking to AI APP which can help you deal with your problem during break time. \\\n",
    "                            This is your persona: {persona}\\\n",
    "                            Please play the role according to the scenario: {scenario}\\\n",
    "                            Use Action → Answer structure for responses.\\\n",
    "                            Available Actions:\\\n",
    "                            1. say: respond base on persona and scenario\\\n",
    "                            2. leave: leave the chat when you think the conversation is over, no need to continue\\\n",
    "                            Examples:\\n{example}'\n",
    "        # print(systemPrompt)\n",
    "\n",
    "        self.messages = [\n",
    "            {'role': 'system', 'content': systemPrompt}, \n",
    "        ]\n",
    "        self.leaveChat = False\n",
    "    \n",
    "    def say(self):\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=self.messages,\n",
    "            response_format={\n",
    "                'type': 'json_schema',\n",
    "                'json_schema': \n",
    "                    {\n",
    "                        \"name\":\"whocares\", \n",
    "                        \"schema\": UserResponse.model_json_schema()\n",
    "                    }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        message = response.choices[0].message.content\n",
    "        self.messages.append({'role': 'assistant', 'content': message})\n",
    "\n",
    "        # str to dict\n",
    "        message = json.loads(message)\n",
    "        self.leaveChat = (message['action'] == 'leave')\n",
    "\n",
    "        info = {\n",
    "            'token': response.usage.total_tokens,\n",
    "        }\n",
    "        \n",
    "        return message['answer'], info\n",
    "    \n",
    "    def listen(self, message: str):\n",
    "        self.messages.append({'role': 'user', 'content': message})\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('What does this app do?', {'token': 372})\n"
     ]
    }
   ],
   "source": [
    "test = Person(SCENARIO_ID, PERSONA)\n",
    "ans = test.say()\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sparkyActionV0(str, Enum):\n",
    "    call_bruno = \"call_bruno\"\n",
    "    call_bizy = \"call_bizy\"\n",
    "    ask_more = \"ask_more\"\n",
    "    introduce_bruno = \"introduce_bruno\"\n",
    "    introduce_bizy = \"introduce_bizy\"\n",
    "    advise = \"advise\"\n",
    "\n",
    "class sparkyActionV1(str, Enum):\n",
    "    guide_to_bruno = \"guide_to_bruno\"\n",
    "    guide_to_bizy = \"guide_to_bizy\"\n",
    "    explore = \"explore\"\n",
    "    introduce_bruno = \"introduce_bruno\"\n",
    "    introduce_bizy = \"introduce_bizy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bizyActionV0(str, Enum):\n",
    "    greet = \"greet\"\n",
    "    start_analysis = \"start_analysis\"\n",
    "    analysing = \"analysing\"\n",
    "    finish_analysis = \"finish_analysis\"\n",
    "    ask_excuse = \"ask_excuse\"\n",
    "    change_excuse = \"change_excuse\"\n",
    "    advise = \"advise\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentResponse(BaseModel):\n",
    "    action: bizyActionV0\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "class Animal:\n",
    "    def __init__(self, name, version: str):\n",
    "\n",
    "        self.agent_name = name\n",
    "        agentFile = open(f'./agent/{name}_{version}.txt', 'r')\n",
    "        agentPrompt = agentFile.read()\n",
    "        agentFile.close()\n",
    "\n",
    "        # create assistant and thread\n",
    "        self.assistant = client.beta.assistants.create(\n",
    "            name = self.agent_name,\n",
    "            instructions = agentPrompt,\n",
    "            model=\"gpt-4o-mini\",\n",
    "            response_format={\n",
    "                'type': 'json_schema',\n",
    "                'json_schema': \n",
    "                    {\n",
    "                        \"name\":\"whocares\", \n",
    "                        \"schema\": AgentResponse.model_json_schema()\n",
    "                    }\n",
    "            }\n",
    "        )\n",
    "        self.thread = client.beta.threads.create()\n",
    "        self.user_message = 'hello'\n",
    "    \n",
    "    def create_thread(self):\n",
    "        self.thread = client.beta.threads.create()\n",
    "\n",
    "    def say(self):\n",
    "\n",
    "        prompt = client.beta.threads.messages.create(\n",
    "            thread_id = self.thread.id,\n",
    "            role = \"user\",\n",
    "            content = self.user_message\n",
    "        )\n",
    "\n",
    "        run = client.beta.threads.runs.create_and_poll(\n",
    "            thread_id=self.thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "        )\n",
    "\n",
    "        while True:\n",
    "            runData = client.beta.threads.runs.retrieve(\n",
    "                thread_id=self.thread.id,\n",
    "                run_id=run.id\n",
    "            )\n",
    "\n",
    "            if runData.status == 'completed': \n",
    "                response = client.beta.threads.messages.list(\n",
    "                    thread_id=self.thread.id\n",
    "                )\n",
    "                message = json.loads(response.data[0].content[0].text.value)\n",
    "\n",
    "                info = {\n",
    "                    'token': runData.usage.total_tokens,\n",
    "                    'action': message['action']\n",
    "                }\n",
    "                return message['answer'], info\n",
    "\n",
    "            else:\n",
    "                print(\"runData.status\")\n",
    "                time.sleep(2) \n",
    "\n",
    "\n",
    "    def listen(self, message: str):\n",
    "        self.user_message = message\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Buzz! Hello there! I'm Bizy, your energetic forest friend ready to help you tackle procrastination and manage your time. How can I assist you today?\", {'token': 847, 'action': 'introduce_bizy'})\n",
      "(\"Buzz buzz, feeling tired can be tough! What's your current excuse for putting off your tasks? Let's dive in and see how we can shift that mindset!\", {'token': 899, 'action': 'ask_excuse'})\n"
     ]
    }
   ],
   "source": [
    "test = Animal(name = AGENT_NAME, version='V0')\n",
    "print(test.say())\n",
    "test.listen('i feel tired')\n",
    "print(test.say())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class responseType(str, Enum):\n",
    "    perfectly_match = \"Perfectly Match\"\n",
    "    good_response = \"Good Response\"\n",
    "    bad_response = \"Bad Response\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class EvaluatorResponse(BaseModel):\n",
    "    accuracy: int\n",
    "    practicality: int\n",
    "\n",
    "class OverallEvaluatorResponse(BaseModel):\n",
    "    type: responseType\n",
    "    reason: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "class Evaluator():\n",
    "    def __init__(self, agentName: str, scenarioID: int) -> None:\n",
    "\n",
    "        systemPrompt = '''You are an evaluator. I will provide you with a user’s statement and an agent’s response.\n",
    "                            You should evaluate the accuracy and practicality base on the scenario.\n",
    "                            - Accuracy: Score from 0 to 10. This measures whether the model’s response appropriately addresses the user’s statement.\n",
    "                            - Practicality: Score from 0 to 10. This evaluates whether the model’s suggestion is helpful to the user.\n",
    "                        '''\n",
    "        \n",
    "        with open(f'./evaluator/{agentName}/scenario{scenarioID}.txt', 'r') as file:\n",
    "            systemPrompt += file.read()\n",
    "        with open(f'./evaluator/examples.txt', 'r') as file:\n",
    "            systemPrompt += file.read()\n",
    "    \n",
    "        self.messages = [\n",
    "            {'role': 'system', 'content': systemPrompt}, \n",
    "        ]\n",
    "        \n",
    "    def evaluate(self, personMessage: str, animalMessage: str):\n",
    "        self.messages.append({'role': 'user', 'content': f'User: {personMessage}\\nAgent: {animalMessage}'})\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=self.messages,\n",
    "            response_format={\n",
    "                'type': 'json_schema',\n",
    "                'json_schema': \n",
    "                    {\n",
    "                        \"name\":\"whocares\", \n",
    "                        \"schema\": EvaluatorResponse.model_json_schema()\n",
    "                    }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        message = json.loads(response.choices[0].message.content)\n",
    "    \n",
    "        return message['accuracy'], message['practicality']\n",
    "    \n",
    "    def overall_evaluate(self, dialogues: list, agentName, scenarioID):\n",
    "        overall_systemPrompt = ''' You are an evaluator. Now You have to evaluate agent's behavior.\n",
    "                                I will provide you a scenario with expect agent behaviors and a dialogue contains user's statement and an agent's response.\n",
    "                                User's question and answer might lead to different types of agent responses. So it's important to consider both scenario expect behavior and the whole dialogue before making a decision.\n",
    "                                You should classify the agent's response into one of the following types:\n",
    "                                1. 'Perfectly Match' : Match at least one of the expected agent behaviors we provided.\n",
    "                                2. 'Good Response' : Didn't match any of the expected agent behavior we provided, but still a good response that can help the user.\n",
    "                                3. 'Bad Response' : Didn't match the expected agent behavior we provided, and can not help the user or not practical.\n",
    "\n",
    "                                For Reason, please be concise and brief, reply less than 15 words. \n",
    "                                    Perfectly Match: Match which behavior.\n",
    "                                    Good Response: How it can help the user.\n",
    "                                    Bad Response: Why it can not help the user.\n",
    "                                **Perform action call/guide_to directly without introduce is definetly bad response.**\n",
    "                            '''\n",
    "        # overall_systemPrompt += '''\n",
    "        #     Scenario:\n",
    "        #     - Description: You are facing difficulties or feeling down in a romantic relationship and seeks emotional support.\n",
    "        #     - Expect Agent Behavior:\n",
    "        #         1. Provide emotional support.\n",
    "\n",
    "        #     Example1:\n",
    "        #     User: I'm feeling really sad because my relationship isn't going well. Is there anything that could help comfort me?,\n",
    "        #     Agent: I'm really sorry to hear that! I know a wonderful owl named Bruno who specializes in mindfulness and relaxation. Would you like to meet him for some comfort and techniques to help you through this?,714,9,8\n",
    "        #     User: \"Yes, meeting Bruno sounds lovely! I would love to get some comfort and mindfulness techniques from him.\",\n",
    "        #     Agent: Fantastic! Bruno will be thrilled to help you find some comfort and mindfulness techniques. Let's go see him now!,775,8,9\n",
    "\n",
    "        #     Score: 'Good Response'\n",
    "\n",
    "        #     Example2:\n",
    "        #     User: I'm feeling really sad because my relationship isn't going well. Is there anything that could help comfort me?\n",
    "        #     Agent: Sorry for hearing that. Maybe you can try to talk to bizy, he might have some good advice for you.\n",
    "\n",
    "        #     Score: 'Bad Response'\n",
    "\n",
    "        #     Example3:\n",
    "        #     User: I'm feeling really sad because my relationship isn't going well. Is there anything that could help comfort me?\n",
    "        #     Agent: It sounds like you’re going through a tough time, and that’s completely valid. Don't forget to care for yourself and seek support from friends or family. It’s okay to give yourself time to work through everything. You’re not alone in this!\n",
    "        #     Score: 'Perfactly Match'\n",
    "        # '''\n",
    "\n",
    "        prompt = ''\n",
    "        with open(f'./evaluator/{agentName}/scenario{scenarioID}.txt', 'r') as file:\n",
    "            prompt += 'Scenario:\\n' + file.read()\n",
    "        \n",
    "        with open(f'./evaluator/{agentName}/{agentName}_eval.txt', 'r') as file:\n",
    "            prompt += 'Agent Introduction:\\n' + file.read()\n",
    "        \n",
    "        dialogue = '\\n'.join(dialogues)\n",
    "        prompt += 'Dialogue:\\n' + dialogue\n",
    "        \n",
    "        message = [\n",
    "            {'role': 'system', 'content': overall_systemPrompt},\n",
    "            {'role': 'assistant', 'content': prompt}\n",
    "        ]\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=message,\n",
    "            response_format={\n",
    "                'type': 'json_schema',\n",
    "                'json_schema': \n",
    "                    {\n",
    "                        \"name\":\"whocares\", \n",
    "                        \"schema\": OverallEvaluatorResponse.model_json_schema()\n",
    "                    }\n",
    "            }\n",
    "        )\n",
    "\n",
    "        message = json.loads(response.choices[0].message.content)\n",
    "        print(message)\n",
    "        return message['type'], message['reason']\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Perfectly Match', 'reason': \"Introduced Bruno and suggested interaction to address user's stress.\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Perfectly Match',\n",
       " \"Introduced Bruno and suggested interaction to address user's stress.\")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialogue = ['user: What does this app do?', 'agent: This app is here to connect you with friendly animal specialists who can help you with various challenges! Whether it\\'s stress, procrastination, or making friends, we\\'ve got furry and buzzing friends ready to lend a paw or wing!', 'user+ How can you help me?', 'agent: What are you struggling with right now? Whether it\\'s stress, procrastination, or something else, I can introduce you to the perfect animal specialist!', 'user :I\\'m not sure yet, but I would like to find something to help with stress.', 'agent: I have just the friend for you! Meet Bruno, the mindfulness master bear who can help you find calm and tackle stress—would you like to chat with him?', 'user: Yes, I would love to chat with Bruno and learn how to tackle stress!', 'agent: Fantastic! Bruno is waiting for you, ready to share his peaceful paws and calming wisdom. Get ready to relax and unwind!']\n",
    "evaluator = Evaluator(agentName = 'sparky', scenarioID = 1)\n",
    "evaluator.overall_evaluate(dialogue, 'sparky', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Evaluator(AGENT_NAME, SCENARIO_ID)\n",
    "test.evaluate('What does this app do?', 'I do not know')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "class Report():\n",
    "    def __init__(self) -> None:\n",
    "        self.finish = True\n",
    "        self.chatHistory = []\n",
    "\n",
    "    def addHistory(self, chat):\n",
    "        self.chatHistory.append(chat)\n",
    "    \n",
    "    def generateReport(self, filename:str):\n",
    "        df = pd.DataFrame(self.chatHistory)\n",
    "        df.to_csv(f'{filename}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKEN = 6000\n",
    "MAX_CHAT = 10\n",
    "SCENARIO_ID = 1\n",
    "PERSONA = 'emma'\n",
    "AGENT_NAME = 'bizy'\n",
    "PROMPT_VERSION = 'V0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/23 [00:37<13:52, 37.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Perfectly Match', 'reason': 'Analyzes procrastination and offers practical strategies to overcome it.'}\n",
      "6512 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 2/23 [01:37<17:40, 50.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Perfectly Match', 'reason': 'Provided structured study plan and motivation tips as expected.'}\n",
      "6785 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 3/23 [02:24<16:17, 48.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Perfectly Match', 'reason': 'Suggested breaking tasks into smaller, manageable steps.'}\n",
      "6601 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 4/23 [03:08<14:51, 46.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Perfectly Match', 'reason': 'Provided strategies for enhancing productivity and learning efficiency.'}\n",
      "5322 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 5/23 [04:57<20:51, 69.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Good Response', 'reason': 'Encourages starting small, which helps alleviate overwhelm.'}\n",
      "8996 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 6/23 [06:08<19:48, 69.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Bad Response', 'reason': 'Response lacks suggestions for improving the learning environment.'}\n",
      "6769 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 7/23 [06:57<16:51, 63.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Perfectly Match', 'reason': 'Provided methods to increase learning motivation and celebrate mini-wins.'}\n",
      "6666 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 8/23 [07:47<14:45, 59.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Good Response', 'reason': 'Encourages positive study habits but lacks specific time-tracking tool suggestions.'}\n",
      "6497 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 9/23 [08:18<12:55, 55.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'Perfectly Match', 'reason': 'Provided strategies for time estimation and buffer time.'}\n",
      "2860 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './user/bizy/scenario10.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m trange(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m24\u001b[39m):\n\u001b[0;32m      8\u001b[0m     SCENARIO_ID \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m----> 9\u001b[0m     person \u001b[38;5;241m=\u001b[39m \u001b[43mPerson\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscenarioID\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mSCENARIO_ID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpersona\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mPERSONA\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# animal = Animal(name= AGENT_NAME)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     animal\u001b[38;5;241m.\u001b[39mcreate_thread()\n",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m, in \u001b[0;36mPerson.__init__\u001b[1;34m(self, scenarioID, persona)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, scenarioID: \u001b[38;5;28mint\u001b[39m, persona: \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m----> 5\u001b[0m     scenarioFile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./user/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mAGENT_NAME\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/scenario\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mscenarioID\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     scenario \u001b[38;5;241m=\u001b[39m scenarioFile\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m      7\u001b[0m     scenarioFile\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\hsuan\\anaconda3\\envs\\fauanTest\\lib\\site-packages\\IPython\\core\\interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    282\u001b[0m     )\n\u001b[1;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './user/bizy/scenario10.txt'"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "overall_evaluate = []\n",
    "animal = Animal(name= AGENT_NAME, version= PROMPT_VERSION)\n",
    "\n",
    "for i in trange(1,24):\n",
    "\n",
    "    SCENARIO_ID = i\n",
    "    person = Person(scenarioID = SCENARIO_ID, persona = PERSONA)\n",
    "    # animal = Animal(name= AGENT_NAME)\n",
    "    animal.create_thread()\n",
    "    evaluator = Evaluator(agentName= AGENT_NAME, scenarioID= SCENARIO_ID)\n",
    "    report = Report()\n",
    "\n",
    "    totalToken = 0\n",
    "    totalChat = 0\n",
    "    dialogue = []\n",
    "\n",
    "    while not person.leaveChat:\n",
    "        # chat\n",
    "        personMessage, personInfo = person.say()\n",
    "        animal.listen(personMessage)\n",
    "        animalMessage, animalInfo = animal.say()\n",
    "        person.listen(animalMessage)\n",
    "\n",
    "        # print(f'User: {personMessage}\\nAgent: {animalMessage}')\n",
    "        # print(f'user leave chat: {person.leaveChat}')\n",
    "\n",
    "        # metrics\n",
    "        accuracy, practicality = evaluator.evaluate(personMessage, animalMessage)\n",
    "        # print(f'Accuracy: {accuracy}, Practicality: {practicality}\\n')\n",
    "        \n",
    "        history = {\n",
    "            'person_say': personMessage,\n",
    "            'animal_action': animalInfo['action'],\n",
    "            'animal_say': animalMessage,\n",
    "            'animal_token': animalInfo['token'],\n",
    "            'accuracy': accuracy,\n",
    "            'practicality': practicality,\n",
    "        }\n",
    "        dialogue.append(f'user: {personMessage}, agent: {animalMessage}')\n",
    "\n",
    "        report.addHistory(history)\n",
    "        totalChat += 1\n",
    "        totalToken += animalInfo['token']\n",
    "\n",
    "        if totalToken > MAX_TOKEN or totalChat > MAX_CHAT:\n",
    "            report.finish = False\n",
    "            break\n",
    "\n",
    "    report.generateReport(filename=f'report_{AGENT_NAME}_{SCENARIO_ID}')\n",
    "    \n",
    "    classification = evaluator.overall_evaluate(dialogue, AGENT_NAME, SCENARIO_ID)\n",
    "    overall_evaluate.append(classification)\n",
    "    \n",
    "    print(totalToken, totalChat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f'{AGENT_NAME}_{PROMPT_VERSION}_overall_evaluate.csv'\n",
    "\n",
    "df = pd.DataFrame(overall_evaluate, columns=['type', 'reason'])\n",
    "df.insert(0, 'scenario_id', range(1, len(df) + 1))\n",
    "\n",
    "df.to_csv(file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fauanTest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
